## YOLO v1

They reframe object detection as a single regression problem, straight from image pixels to bounding box coordinates and class probabilities. Using this system, we only look once(YOLO) at an image to predict what objects are present and where they are. YOLO is refreshingly simple. Next figure show that single CNN simultaneously predicts multiple bounding boxes and class probabilities for those boxes. YOLO trains on full images and directly optimizes detection performance. This unified model has several benefits over tranditional methods of object detection. 

(figure1 사진)

First, YOLO is extremly fast. Since authors frame detection as a regression problem they don't need a complex pipeline. Second, YOLO reasons globally about the image when making predictions. Unlikke sliding window and region propoals based techneiques, YOLO sees the entire image during training and test time so it implicitly encodes contextual information about classes as weel as their appearance. Third, YOLO learns generalizable representations of objects. When trained on natural images and tested on artwork, YOLO outperforms top detection methods like DPN and R-CNN by a wide margin.

#### Unified Detection

This network uses features from the entire image to predict each boundig box. It also predicts all bounding boxes across all classes for an image simultaneously. This YOLO design enables end-to-end training and real time speeds while maintaining high average precision. This system divides the input image into an S x S grid. If the center of an object falls into a grid cell, that grid cell is responsible for detection that object. Each grid cell predicts 'B' bounding boxes and confidence scores for those boxes. These confidence score reflect how confident the model is that box contains an object and also how accurate it thinks the box is that it predicts. Formally they define confidence as "Pr(object) x IOU(truth predict)". Each bounding box consists of 5 Predictions: x,y,w,h, and confidence. (x,y) coordinates represent the center of the box relative to the bounds of the grid cell. The width and height are predicted relative to the whole image. Finally the confidence prediction represents the IOU between the predicted box and any ground truth box.
