## Faster R-CNN

Although region-based CNNs were computationally expensive as originally developed, their cost has been drastically reduced thanks to sharing convolutions across proposals. The latest incarnation, Fast R-CNN achieves near real time rates using very deep networks, when ignoring the ime spent on region proposals. Selective search, one of the most popular methods, greedily merges superpixels based on engineered low level features. Yet when compared to efficient detection networks, Selective search is an order of magnitude slower, at 2 seconds per image in a CPU implementation. EdgeBoxes currently provides the best tradeoff between proposal quality and speed, at 0.2 seconds per image. Nevertheless, the region proposal step still consumes as much running time as the detection network. 
 
 In this paper, they show that an algorithmic change leads to an elegant and effective solution where proposal computation is nearly cost-free given the detection network's computation. To this end, they introduce novel _Region Proposal Network_(RPNs) that share convolutional laers with state-of-the-art object detection networks. By sharing convolutions at test time, the marginal cost for computing proposals is small.(10ms per image). Their observation is that the convolutional feature maps used by region-based detectors, like Fast R-CNN, can also be used for generating region proposals. On top of these convolutional features, they construct an RPN by adding a few additional convolutional layers that simultanesously regress region bounds and objectness scores at each location on a regular grid. The RPN is thus a kind of fully convolutional network and can be trained end-to-end specifically for the task for generating detection proposals. 
 
 RPNs are designed to efficiently predict region proposals with a wide range of scales and aspect ratios. In contrast to prevalent methods that use pyramids of images or pyramids of filters, they introduce novel 'anchor' boxes that seve as references at multiple scales and aspect ratios. This model performs well when trained and tested using single scale iages and thus benefits running speed. To unify RPNs with Fast R-CNN object detection networks, they propose a training scheme that alternates between fine-tuning for the region proposal task and then fine-tuning for object detection, while keeping the proposals fixed. RPNs completely learn to propose regions from data, and thus can easily benefit from deeper and more expensive features.
 
 Their object detection system, called Faster R-CNN, is composed of two modules. THe first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector that uses the proposed regions. The entrire systems is a single, unified network for object detection. Using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN module tells the Fast R-CNN module where to look.(Figure2_
