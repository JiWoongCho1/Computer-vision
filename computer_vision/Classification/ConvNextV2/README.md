## ConvNextV2

The performance of a visual representation learning system is largely influenced by three main factors: the neural network architecture chosen, the method used for training the network, and the data used for training. Innovation in neural network architecture design has consistently played a major role in the field of representation learning. Convolutional neural network architectures have had a significant impact on computer vision research by allowing for the use of generic feature learning methods for a variety of visual recognition tasks, rather than relying on manual feature engineering. More recently, ConvNeXt architecture has modernized tranditional CNNs and demonstrated that pure convolutional models could also be scalable architectures. However, the mose common method for exploring the design space for neural network architectures is still through benchmarking supervised learning performance on ImageNet.


In a separate line of research, the focus of visual representation learning has been shifting from supervised learning with labels to self-supervesied pre-training with pretext objectives. Among many different self-supervised algorithms, masked autoencoders(MAE) have recently brought success in masked language modeling to the vision domain and quickly become a popular approach for visual representation learning. In fact, previous research has shown that training CNNs with mask-based self-supervised learning can be difficult, and empirical evidence suggests that transformers and CNNs may have different feature learning behaviors that can affect representation quality. So authors propose to _co-design_ the network architecture and the masked autoencoder under the same framework, with the aim of making mask-based self supervised learning effecitve for CNNs models and achieving results similar to those obtained using transformers. In designing the masked autoencoder, they treat the masked input as a set of sparse patches and use sparse convolutions to process only the visible parts.
