## Hello Computervision!

#### This repository is papers that contribute the computer vision that i read. 

# Contents

- [Image Classification](#image-classification)
- [Segmentation](#segmentation)
- [Generative Model](#generative)
- [Object detection](#detection)
- [Self-supervised learning](#selfsupervised)
- [NLP(National Language Processing)](#nationallanguage)


-----------------------------------------------------------------------------------

## Image Classification  <a name= "image-classification"></a>

- Lenet(Gradient Based Learning Applied to Document Recognition, 1998) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/Lenet"> Code ,</A>  <A href = "http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/Lenet"> Paper Review</A>
- AlexNet(ImageNet Classfication with Deep Convolutional Neural Networks, 2012) <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/AlexNet"> Code, </A> <A href = "https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/AlexNet"> Paper Review</A> 

- VGGNet(Very Deep Convolutional Networks for Large Scale Image Resoultion, 2015) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/VGGNet"> Code, </A> <A href = "https://arxiv.org/pdf/1409.1556.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/VGGNet"> Paper Review</A>

- SPPNet(Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, 2014) <A href = "@article{ouyang2018pedestrian,
  title={Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond},
  author={Ouyang, Xi and Cheng, Yu and Jiang, Yifan and Li, Chun-Liang and Zhou, Pan},
  journal={arXiv preprint arXiv:1804.02047},
  year={2018}
}"> Code, </A> <A href = "https://arxiv.org/pdf/1406.4729.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/SPPNet"> Paper Review</A>

- GoogleNet(Going deeper with convolutions, 2015) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/GoogleNet"> Code, </A> <A href = "https://arxiv.org/pdf/1409.4842.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/GoogleNet"> Paper Review</A> 

- ResNet(Deep residual Learning for Image Recognition, 2016) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/ResNet"> Code, </A> <A href = "https://arxiv.org/pdf/1512.03385.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/ResNet"> Paper Review</A>

- SqueezeNet(Alexnet-Level accuracy with 50x fewer parameters and 0.5MB model size, 2017) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/SqueezeNet"> Code, </A> <A href = "https://arxiv.org/pdf/1602.07360.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/SqueezeNet"> Paper Review</A> 

- DenseNet(Densely Connected Convolutional Networks, 2017) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/DenseNet"> Code, </A> <A href = "https://arxiv.org/pdf/1608.06993.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/DenseNet"> Paper Review</A>

- XceptionNet(Xception: Deep Learnning with depthwise separable convolutions, 2017) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/XceptionNet"> Code, </A> <A href = "https://arxiv.org/pdf/1610.02357.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/XceptionNet"> Paper Review</A> 

- MobileNetV1(MobileNets: Efficient Convolutional Neural networks for mobile vision application, 2017) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/MobileNetV1"> Code, </A> <A href = "https://arxiv.org/pdf/1704.04861.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/MobileNetV1"> Paper Review</A> 

- ShuffleNet(ShuffleNet: An extremlely efficient convolutional neural networks for mobile devices, 2017) <A href = "https://github.com/jaxony/ShuffleNet"> Code, </A> <A href = "https://arxiv.org/pdf/1707.01083.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/ShuffleNet"> Paper Review</A>

- ResNext(Aggregated Residual Transormations for Deep Neural Networks, 2017) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/ResNext"> Code, </A> <A href = "https://arxiv.org/pdf/1611.05431.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/ResNext"> Paper Review</A>

- MobileNetV2(MobileNetV2: Inverted residual and linear bottlenecks, 2018) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/MobileNetV2"> Code, </A> <A href = "https://arxiv.org/pdf/1801.04381.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/MobileNetV2"> Paper Review</A>

- Squeeze Excitation Network(Squeeze and Excitation Network, 2018) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/SENet"> Code, </A> <A href = "https://arxiv.org/pdf/1709.01507.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/SENet"> Paper Review</A>

- Residual Attention Network(Residual Attention Network for image classification, 2017) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/ResidualAttentionNet"> Code, </A> <A href = "https://arxiv.org/pdf/1704.06904.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/ResidualAttentionNet"> Paper Review</A> 

- BAM(BottleNeck Attention Module, 2018) <A href = "https://github.com/Jongchan/attention-module"> Code, </A> <A href = "https://arxiv.org/abs/1807.06514">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/BAM"> Paper Review</A> 

- CBAM(CBAM: Convolutional Block Attention Module, 2018) <A href = "https://github.com/Jongchan/attention-module"> Code, </A> <A href = "https://arxiv.org/pdf/1807.06521.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/CBAM"> Paper Review</A> 

- EfficientNet(EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, 2019) <A href = "https://github.com/lukemelas/EfficientNet-PyTorch"> Code, </A> <A href = "https://arxiv.org/pdf/1905.11946.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/EfficientNet"> Paper Review</A>

- Vision Transformer(An Image is worth 16x16 words: Transformers for image recognition at scale, 2020) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/VisionTransformer"> Code, </A> <A href = "https://arxiv.org/pdf/2010.11929.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/VisionTransformer"> Paper Review</A>

- Swin Transformer(Swin Transformer, Hierarchical Vision Transformer using Shifted Windows, 2021) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/SwinTransformer"> Code, </A> <A href = "https://arxiv.org/pdf/2103.14030.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/SwinTransformer"> Paper Review</A>

- Hybrid Swin Transformer(Hybrid Swin Transformer: Efficient large-scale image retrieval with deep feature orthogonality and Hybrid-Swin-Transformers, 2021) <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/Classification/HybridSwinTransformer"> Code, </A> <A href = "https://arxiv.org/pdf/2110.03786.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/HybridSwinTransformer"> Paper Review</A> 

- ConvNext(A ConvNet for the 2020s, 2022) <A href = "https://github.com/facebookresearch/ConvNeXt"> Code, </A> <A href = "https://arxiv.org/pdf/2201.03545.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/ConvNext"> Paper Review</A> 

- ConvNextV2(ConvNextV2: Co-designing and Scaling ConvNets with Masked Autoencoders, 2022) <A href = "https://github.com/facebookresearch/ConvNeXt-V2/tree/main/models"> Code, </A> <A href = "https://arxiv.org/pdf/2301.00808.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/Computer-vision/tree/main/computer_vision/Classification/ConvNextV2"> Paper Review</A> 


## Object Detection <a name= "detection"></a>

- R-CNN(Rich feature hierarchies for accurate object detection and semantic segmentation, 2014) <A href = "https://github.com/object-detection-algorithm/R-CNN"> Code, </A> <A href = "https://arxiv.org/pdf/1311.2524.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Obeject%20Detection/R-CNN"> Paper Review</A> 

- Fast R-CNN(Fast R-CNN, 2015) <A href = "https://github.com/rbgirshick/fast-rcnn"> Code, </A> <A href = "https://arxiv.org/pdf/1504.08083.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Obeject%20Detection/Fast%20R-CNN"> Paper Review</A> 

- Faster R-CNN(Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, 2015) <A href = "https://github.com/jwyang/faster-rcnn.pytorch"> Code, </A> <A href = "https://arxiv.org/pdf/1506.01497.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Obeject%20Detection/Faster%20R-CNN"> Paper Review</A>

- YOLO V1(You Only Look Once: Unified, Real-Time Object Detection, 2016) <A href = "https://github.com/abeardear/pytorch-YOLO-v1"> Code, </A> <A href = "https://arxiv.org/pdf/1506.02640.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Obeject%20Detection/YOLO"> Paper Review</A>

- SSD(SSD: Single Shot MultiBox Detector, 2016) <A href = "https://github.com/amdegroot/ssd.pytorch"> Code, </A> <A href = "https://arxiv.org/pdf/1512.02325.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Obeject%20Detection/SSD"> Paper Review</A>

- FPN(Feature Pyramid Networks for Object Detection, 2016) <A href = "https://github.com/jwyang/fpn.pytorch"> Code, </A> <A href = "https://arxiv.org/pdf/1612.03144.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Obeject%20Detection/FPN"> Paper Review</A>


## Segmentation <a name= "segmentation"></a>


- Deeplab v1(Semantic image segmentation with deep convolutional nets and fully connected CRFs, 2014) <A href = "https://github.com/abeardear/pytorch-YOLO-v1"> Code, </A> <A href = "https://arxiv.org/pdf/1412.7062.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Segmentation/DeepLab%20v1"> Paper Review</A>

- FCN(Fully Convolutional Networks for Semantic Segmentation, 2014) <A href = "https://github.com/wkentaro/pytorch-fcn"> Code, </A> <A href = "https://arxiv.org/pdf/1411.4038.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Segmentation/FCN"> Paper Review</A>

- SegNet(SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation, 2015) <A href = "https://github.com/vinceecws/SegNet_PyTorch"> Code, </A> <A href = "https://arxiv.org/pdf/1511.00561.pdf">Paper Link, </A> <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Segmentation/FCN"> Paper Review</A>

- Segformer(SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers, 2021) <A href = "https://github.com/NVlabs/SegFormer"> Code, </A> <A href = "https://arxiv.org/pdf/2105.15203.pdf">Paper Link, </A>  Paper Review


## Generative Model <a name= "generative"></a>
- GAN(Generative Adversarial Network, 2014) :<A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/GAN.ipynb"> Code ,</A>  <A href = "https://arxiv.org/abs/1406.2661">Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/8"> Paper Review</A>

- DCGAN(Deep Convolutional Generative Adversarial Network, 2016) : <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/DCGAN.ipynb">Code ,</A>  <A href = "https://arxiv.org/abs/1511.06434">Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/10"> Paper Review</A>
  
- cGAN(Conditional Generative Adversarial Network, 2014) :<A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/cGAN.ipynb"> Code ,</A>  <A href = "https://arxiv.org/abs/1411.1784">  Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/12"> Paper Review</A>

- LSGAN(Least Square Generative Adversarial Network, 2017) : Code ,</A>  <A href = "https://arxiv.org/abs/1611.04076">  Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/21"> Paper Review</A>

- InfoGAN(Information Maximizing Generative Adversarial Network, 2016) : Code ,</A>  <A href = "https://arxiv.org/abs/1606.03657">  Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/27"> Paper Review</A>

- WGAN(Wasserstein GAN, 2017) : <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/wGAN.ipynb">Code ,</A>  <A href = "https://arxiv.org/abs/1701.07875">  Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/32"> Paper Review</A>

- CycleGAN(Cycle Consistent GAN, 2017):<A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/CycleGAN.ipynb"> Code ,</A>  <A href = "https://arxiv.org/abs/1703.10593">  Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/42"> Paper Review</A>

- U-Net(U-Net, 2015): <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/U-Net.ipynb">Code ,</A>  <A href = "https://arxiv.org/abs/1505.04597">  Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/45"> Paper Review</A>
  
- Pix2Pix(Image to Image Translation with Conditional Adversarial Networks, 2016) :<A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/Pix2Pix.ipynb"> Code ,</A>  <A href = "https://arxiv.org/pdf/1611.07004.pdf"> Paper Link, </A>  <A href = "https://keepgoingrunner.tistory.com/46"> Paper Review</A>

- AutoEncoder(2011) :<A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/AutoEncoder.ipynb"> Code</A>  
  
- StyleTransfer(2015) : <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/Style_Transfer.ipynb"> Code ,</A>  <A href = "https://arxiv.org/pdf/1508.06576.pdf">  Paper Link </A> <A href = "https://keepgoingrunner.tistory.com/61"> Paper Review</A>
  
- AdaIN Style Transfer(Adaptive Instance Normalization, 2017) : <A href = "https://github.com/JiWoongCho1/Computer-vision/blob/main/computer_vision/generative_model/AdaIN%20Style%20Transfer.ipynb"> Code ,</A>   <A href = "https://arxiv.org/abs/1703.06868"> Parper Link </A>

- VAE(AutoEncoding Variational Bayes, 2014) : <A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/generative_model"> Code ,</A>   <A href = "https://arxiv.org/pdf/1312.6114.pdf"> Parper Link </A>


## NLP <a name="nationallanguage"></a>
- Attention(Neural Machine Translation By Jointly Learning to Align and translate, 2015) : Code ,</A>  <A href = "https://arxiv.org/abs/1409.0473">Paper Link, </A> <A href = "https://keepgoingrunner.tistory.com/manage/newpost/69?type=post&returnURL=https%3A%2F%2Fkeepgoingrunner.tistory.com%2Fmanage%2Fposts%2F"> Paper Review</A>

## Self-supervised learning <a name="selfsupervised"></a>

- SimCLR(A Simple Framework for contrastive learning of visual representation, 2020) :<A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Self-Supervised-Learning/SimCLR"> Code ,</A>  <A href = "https://arxiv.org/pdf/2002.05709.pdf">Paper Link, </A> Paper Review</A>

- MocoV1(Momentum contrast for unsupervised visual representation learning, 2020) :<A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Self-Supervised-Learning/MoCoV1"> Code ,</A>  <A href = "https://arxiv.org/pdf/1911.05722.pdf">Paper Link, </A> Paper Review</A>

- BYOL(2020) :<A href = "https://github.com/JiWoongCho1/hello-computervision/tree/main/computer_vision/Self-Supervised-Learning/BYOL"> Code ,</A>  <A href = "https://arxiv.org/abs/2006.07733">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/132"> Paper Review </A>

- SwAV(2020) :<A href = "https://github.com/facebookresearch/swav"> Code ,</A>  <A href = "https://arxiv.org/abs/2006.09882">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/134"> Paper Review </A>

- SimSiam(Exploring Simple siamese representation learning, 2020) :<A href = "https://github.com/facebookresearch/simsiam"> Code ,</A>  <A href = "https://arxiv.org/abs/2011.10566">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/137"> Paper Review </A>

- DINO(Emerging properties in self-supervised vision transformers, 2021) :<A href = "https://github.com/facebookresearch/dino"> Code ,</A>  <A href = "https://arxiv.org/abs/2104.14294">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/138"> Paper Review </A>

- MAE(Masked Autoencoder are scalable vision learners, 2021) :<A href = "https://github.com/facebookresearch/mae"> Code ,</A>  <A href = "https://arxiv.org/abs/2111.06377">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/139"> Paper Review </A>

- PAWS(Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples, 2021) :<A href = "https://github.com/facebookresearch/suncet"> Code ,</A>  <A href = "https://arxiv.org/pdf/2104.13963.pdf">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/139"> Paper Review </A>

- BEiT(BERT Pre-Training of Image Transformers, 2021) :<A href = "https://github.com/microsoft/unilm/tree/master/beit"> Code ,</A>  <A href = "https://arxiv.org/pdf/2106.08254.pdf">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/141"> Paper Review </A>

- SimMIM(SimMIM: a Simple Framework for Masked Image Modeling, 2021) :<A href = "https://github.com/microsoft/SimMIM"> Code ,</A>  <A href = "https://arxiv.org/pdf/2111.09886.pdf">Paper Link </A>, <A href = "https://keepgoingrunner.tistory.com/manage/posts/"> Paper Review </A>

